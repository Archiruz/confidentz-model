{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU6sWQiTFwqj"
      },
      "source": [
        "# Training and Validation Script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2R61SiqFwqm"
      },
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NdzrB4_TFwqm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7jIFotwFwqn"
      },
      "source": [
        "## Import Dataset (Need to be automated and consistent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "xWCNgW5jGzBq",
        "outputId": "e24563c8-0b5d-4024-cddc-0cfeb8b2b30e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tYM-45FgvabZgCORbWcsmAHDQ4s10Eoi\n",
            "To: /content/dataset.zip\n",
            "100%|██████████| 9.15M/9.15M [00:00<00:00, 28.0MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dataset.zip'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = \"https://drive.google.com/file/d/1tYM-45FgvabZgCORbWcsmAHDQ4s10Eoi/view?usp=drive_link\"\n",
        "output = \"dataset.zip\"\n",
        "gdown.download(url, output, quiet=False, fuzzy=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cBspB4saFwqo"
      },
      "outputs": [],
      "source": [
        "# download zip file dataset from https://drive.google.com/drive/folders/1nwR-wo-_9mQtqkVJd3Grhlw6YGPX4EKP?usp=share_link\n",
        "filenames = os.listdir()\n",
        "\n",
        "for file in filenames:\n",
        "  dataset = re.search(r'^dataset.*\\.zip$', file)\n",
        "\n",
        "  if dataset:\n",
        "    zip_path = f'./{file}'\n",
        "    zip_ref = zipfile.ZipFile(zip_path, 'r')\n",
        "    zip_ref.extractall(path='./')\n",
        "    zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9qsua8jFwqo"
      },
      "source": [
        "## ETL (Extract Transform Load)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b5PrUCfQFwqo"
      },
      "outputs": [],
      "source": [
        "# Extract (Specifying path)\n",
        "base_dir = './dataset/'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m9IrDeSFwqp",
        "outputId": "4eab2145-9c54-4155-c55d-7d865093986c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 500 files belonging to 2 classes.\n",
            "Using 400 files for training.\n",
            "Found 500 files belonging to 2 classes.\n",
            "Using 100 files for validation.\n",
            "Found 32 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Extract (Generating dataset from directory)\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = (255, 255)\n",
        "VAL_SPLIT = 0.2\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    # labels='inferred',\n",
        "    # label_mode='binary',\n",
        "    # class_names=None,\n",
        "    # batch_size=BATCH_SIZE,\n",
        "    # image_size=IMAGE_SIZE,\n",
        "    validation_split=VAL_SPLIT,\n",
        "    subset='training',\n",
        "    # shuffle=True,\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    # labels='inferred',\n",
        "    # label_mode='binary',\n",
        "    # class_names=None,\n",
        "    # batch_size=BATCH_SIZE,\n",
        "    # image_size=IMAGE_SIZE,\n",
        "    validation_split=VAL_SPLIT,\n",
        "    subset='validation',\n",
        "    # shuffle=True,\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    # labels='inferred',\n",
        "    # label_mode='binary',\n",
        "    # class_names=['caries', 'no-caries'],\n",
        "    # batch_size=BATCH_SIZE,\n",
        "    # image_size=IMAGE_SIZE,\n",
        "    # shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRxUy2EmVQT3",
        "outputId": "4b156471-aff3-4a61-ba35-5ae3ffb10c45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32, 256, 256, 3)\n",
            "(32,)\n"
          ]
        }
      ],
      "source": [
        "# Check batches' shape\n",
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4c1RcZXFwqs"
      },
      "source": [
        "### Preprocessing Images using keras preprocessing layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "p5TBZZ0gQtmT"
      },
      "outputs": [],
      "source": [
        "# Transform (Preprocessing data)\n",
        "\n",
        "# optimize data I/O\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "IMG_SIZE = 255\n",
        "\n",
        "image = next(iter(train_ds))\n",
        "\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal\",\n",
        "                    input_shape=(IMG_SIZE,\n",
        "                                 IMG_SIZE,\n",
        "                                 3)),\n",
        "  layers.RandomRotation(0.1),\n",
        "])\n",
        "\n",
        "def prepare(ds, shuffle=False, augment=False):\n",
        "  # Resize and rescale all datasets.\n",
        "  ds = ds.map(lambda x, y: (resize_and_rescale(x), y), \n",
        "              num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(1000)\n",
        "\n",
        "  # Use data augmentation only on the training set.\n",
        "  if augment:\n",
        "    ds = ds.map(lambda x, y: (data_augmentation(x), y), \n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  # Use buffered prefetching on all datasets.\n",
        "  return ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Agu1JD9VUqzW"
      },
      "outputs": [],
      "source": [
        "# Load (Apply preprocessing and load data)\n",
        "\n",
        "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
        "val_ds = prepare(val_ds)\n",
        "test_ds = prepare(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COabnFwuFwqs"
      },
      "outputs": [],
      "source": [
        "# experimental ImageDatagenerator for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        # rotation_range=40,\n",
        "        # width_shift_range=0.2,\n",
        "        # height_shift_range=0.2,\n",
        "        # shear_range=0.2,\n",
        "        # zoom_range=0.2,\n",
        "        # horizontal_flip=True,\n",
        "        # fill_mode='nearest'\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB3Ejp5hFwqq"
      },
      "source": [
        "### Building Model using Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfSXNry3Fwqq"
      },
      "outputs": [],
      "source": [
        "# transfer learning not final (maybe can use less layer?)\n",
        "# model_selection = (\"mobilenet_v2\", 224, 1280) \n",
        "# handle_base, pixels, FV_SIZE = model_selection\n",
        "# IMAGE_SIZE = (pixels, pixels)\n",
        "\n",
        "# MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
        "# feature_extractor = hub.KerasLayer(MODULE_HANDLE, input_shape=IMAGE_SIZE + (3,))\n",
        "# feature_extractor.trainable = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z59WQIUSFwqr",
        "outputId": "afab2f89-e7a4-4832-d899-cf650a873092"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Inception V3 model\n",
        "pre_trained_model = InceptionV3(input_shape = (255, 255, 3), \n",
        "                                include_top = False, \n",
        "                                weights = 'imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wya2UF4eFwqr"
      },
      "outputs": [],
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qupOPB0bFwqs"
      },
      "outputs": [],
      "source": [
        "# # not final\n",
        "# model = tf.keras.Sequential([\n",
        "#   feature_extractor,\n",
        "#   tf.keras.layers.Dense(1, activation='sigmoid') # sigmoid/softmax\n",
        "# ])\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "aEy9a7W4Fwqs"
      },
      "outputs": [],
      "source": [
        "x = layers.Flatten()(pre_trained_model.output)\n",
        "# x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Dense(1024, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = tf.keras.Model(pre_trained_model.input, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "5yT5P0ZOFwqs"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  optimizer = optimizers.Adam(learning_rate=0.0001), \n",
        "  loss = 'binary_crossentropy', \n",
        "  metrics = ['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GtHgcicFwqt"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0Vrp8wxFwqt",
        "outputId": "46930186-154f-4e1b-c7e5-f77e18c8f76b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/100 - 85s - loss: 1.0451 - accuracy: 0.8475 - val_loss: 0.1467 - val_accuracy: 0.9600 - 85s/epoch - 845ms/step\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data = val_ds,\n",
        "  steps_per_epoch = 100,\n",
        "  epochs = 5,\n",
        "  validation_steps = 50,\n",
        "  verbose = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC9E9xgbFwqt"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nuu-aoLYFwqt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPXh2AqRFwqt"
      },
      "outputs": [],
      "source": [
        "# change filename to file you want to predict\n",
        "filename = '.jpeg'\n",
        "img = load_img(filename, target_size=(150, 150))\n",
        "x = img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "images = np.vstack([x])\n",
        "classes = model.predict(images, batch_size=10)\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMpSpREAFwqu"
      },
      "source": [
        "## TODO\n",
        "Create save model function"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 ('confidentz')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "725442b4da6b04180f8356525f093bfe3373ff1af9d9abfbace5b678dac2809c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
